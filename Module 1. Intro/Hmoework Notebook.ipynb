{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e0d86ef-7c5b-4cdd-aef6-1dcdedca0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import requests \n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d719f-4480-45fb-b8ce-0b8df127408d",
   "metadata": {},
   "source": [
    "## Connecting to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd5d2d0-e740-429c-add4-a5f858be6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll Use Gemini\n",
    "model=\"gemini-2.5-flash-preview-05-20\"\n",
    "base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "api_key=os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "client = OpenAI(base_url=base_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0da6d5-1254-4bd3-ba21-6407ae336e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the client\n",
    "messages = [{\"role\":\"user\" , \"content\":\"is it late to join the course\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c840d569-4153-429a-890b-0bbd9e3a6921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It really depends on several factors! To give you the best advice, I\\'d need to know:\\n\\n1.  **What kind of course is it?** (e.g., a university semester, a short online workshop, a self-paced certification, a coding bootcamp, a language class)\\n2.  **When did it officially start?** (e.g., last week, a month ago, three months ago)\\n3.  **What is the total duration of the course?** (e.g., 2 weeks, 8 weeks, 16 weeks, ongoing)\\n4.  **How is the course structured?** (e.g., live lectures, pre-recorded videos, assignments, group projects, exams)\\n5.  **Are there any official enrollment deadlines?** (Sometimes you simply can\\'t join after a certain date.)\\n\\n**However, here\\'s a general guide:**\\n\\n**It might be okay if:**\\n\\n*   **Only a small portion has passed:** If it\\'s a long course (e.g., 16 weeks) and only 1-2 weeks have gone by.\\n*   **Content is not heavily cumulative:** If each week\\'s topic is relatively independent.\\n*   **Materials are available:** You can access recordings of missed lectures, notes, readings, and assignments.\\n*   **It\\'s self-paced:** You can catch up on your own schedule.\\n*   **You\\'re a fast learner and highly motivated:** You\\'re confident you can put in the extra effort to catch up quickly.\\n*   **There\\'s good support:** Tutors, TAs, or instructors are available to help you.\\n\\n**It might be too late if:**\\n\\n*   **A significant portion has passed:** (e.g., more than 25-30% of the course duration).\\n*   **Content is highly cumulative:** Each new topic builds heavily on the previous ones (e.g., math, programming, advanced language courses).\\n*   **Live participation is crucial:** Most learning happens in interactive live sessions that you\\'ve missed.\\n*   **Missed foundational concepts:** The early material is essential for understanding everything else.\\n*   **Important deadlines have passed:** You\\'ve missed assignments, quizzes, or project submissions that contribute significantly to your grade/completion.\\n*   **Enrollment is officially closed.**\\n\\n**What you should do:**\\n\\n1.  **Contact the course administrator or instructor IMMEDIATELY.** This is the most important step.\\n2.  **Ask them specific questions:**\\n    *   \"Is it still possible to enroll?\"\\n    *   \"How much material have I missed?\"\\n    *   \"Are recordings/notes/materials from the missed sessions available?\"\\n    *   \"Are there any upcoming deadlines I should be aware of or that I\\'ve already missed?\"\\n    *   \"What would you recommend for catching up if I join now?\"\\n3.  **Review the course syllabus/outline (if available):** This will give you a good idea of what\\'s been covered and what\\'s coming.\\n4.  **Be realistic about your own capacity:** Can you truly commit the extra time and effort required to catch up without getting overwhelmed?\\n\\nDon\\'t assume it\\'s too late without checking! But be prepared to put in extra work if you do join late.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d49f1-0e91-4333-9be7-3ead666cc910",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d720a091-699a-4a9c-9fa8-ca85c766a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcceaf7-9468-441b-944a-7f6c2b02ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47614961-e310-4b98-b4ee-d6f1e21282d7",
   "metadata": {},
   "source": [
    "## Indexing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a58c376e-ac9b-4fed-825c-38c35b59bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72e019fb-8f05-43cd-9f9d-e4f7cb1b2e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'module1-homework-questions'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"module1-homework-questions\"\n",
    "\n",
    "elastic_client.indices.create(index=index_name , body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3efd19a5-2dc5-4616-b356-1645c78c4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 948/948 [00:59<00:00, 16.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    elastic_client.index(index=index_name , document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf90ad-a50e-4317-8ad3-49d676642f88",
   "metadata": {},
   "source": [
    "## Searching in Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d73df28-5ac6-4785-8848-2cf6b2f928d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = elastic_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit)\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b33ddb5-bbda-4d6a-9da0-ccadc8c38802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'module1-homework-questions',\n",
       "  '_id': '7BtsepcBQT9pif-cGpil',\n",
       "  '_score': 44.50556,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'module1-homework-questions',\n",
       "  '_id': 'extsepcBQT9pif-cPJmy',\n",
       "  '_score': 35.433445,\n",
       "  '_source': {'text': 'Deploy and Access the Kubernetes Dashboard\\nLuke',\n",
       "   'section': '10. Kubernetes and TensorFlow Serving',\n",
       "   'question': 'Kubernetes-dashboard',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'module1-homework-questions',\n",
       "  '_id': 'DBtsepcBQT9pif-cIZnV',\n",
       "  '_score': 33.70974,\n",
       "  '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "   'course': 'machine-learning-zoomcamp'}}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do execute a command on a Kubernetes pod?\"\n",
    "elastic_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2401b-f970-4886-9394-59019d513d6b",
   "metadata": {},
   "source": [
    "## Query Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25abf9d2-57cc-4a70-986f-ae00f0657b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 340\n",
      "Top 3 results:\n",
      "\n",
      "Result 1:\n",
      "Question: How do I debug a docker container?\n",
      "Course: machine-learning-zoomcamp\n",
      "Score: 74.31\n",
      "\n",
      "Result 2:\n",
      "Question: How do I copy files from my local machine to docker container?\n",
      "Course: machine-learning-zoomcamp\n",
      "Score: 67.62\n",
      "\n",
      "Result 3:\n",
      "Question: How do I copy files from a different folder into docker container’s working directory?\n",
      "Course: machine-learning-zoomcamp\n",
      "Score: 60.74\n",
      "\n",
      "The 3rd question returned is: 'How do I copy files from a different folder into docker container’s working directory?'\n"
     ]
    }
   ],
   "source": [
    "# Define the search query\n",
    "search_results = elastic_client.search(\n",
    "    index=\"module1-homework-questions\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": \"How do copy a file to a Docker container?\",\n",
    "                            \"fields\": [\"question^4\", \"text\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"term\": {\n",
    "                            \"course\": \"machine-learning-zoomcamp\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 3  # Return only 3 results\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process and display results\n",
    "print(f\"Total matches: {search_results['hits']['total']['value']}\")\n",
    "print(\"Top 3 results:\")\n",
    "for i, hit in enumerate(search_results['hits']['hits'], 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Question: {hit['_source']['question']}\")\n",
    "    print(f\"Course: {hit['_source']['course']}\")\n",
    "    print(f\"Score: {hit['_score']:.2f}\")\n",
    "\n",
    "# Extract the 3rd question\n",
    "if len(search_results['hits']['hits']) >= 3:\n",
    "    third_question = search_results['hits']['hits'][2]['_source']['question']\n",
    "    print(f\"\\nThe 3rd question returned is: '{third_question}'\")\n",
    "else:\n",
    "    print(\"\\nFewer than 3 results were returned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae6b60-78db-4b40-aee3-c7cdce86efe6",
   "metadata": {},
   "source": [
    "## Building a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d50e20f0-5568-4551-9d85-fe74600a1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generat_prompt(question , search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "                \"\"\".strip()\n",
    "    context = \"\"\n",
    "    context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "            \"\"\".strip()\n",
    "    \n",
    "    for doc in search_results:\n",
    "        doc = doc['_source']\n",
    "        context = context + context_template.format(question=doc['question'] , text=doc['text']) + \"\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=question, context=context).strip()\n",
    "    print(prompt.strip())\n",
    "    print(\"Length of the Prompt : \",len(prompt))\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "29b29cd9-9d8b-404b-a59d-fbed38cbf20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: How do copy a file to a Docker container?\n",
      "\n",
      "CONTEXT:\n",
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n",
      "Length of the Prompt :  1446\n"
     ]
    }
   ],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "\n",
    "search_results = elastic_search(query)\n",
    "prompt = generat_prompt(query,search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a6fa5-a170-42de-9017-ffe6a01d3a5a",
   "metadata": {},
   "source": [
    "## Calculate Tokens Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "95c4fe9c-b1dd-40ba-828d-aa73458a35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ead652cc-5439-4b89-9ede-5ac303a5dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f5cdae7-7f7b-457a-af3e-7d82e236656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2c004be-1d01-48c6-9e9f-44c409f242aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 320\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(prompt)\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d2e48-a78b-48f0-b8b4-d19c5996bb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
